{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "603622f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salida del bloque: torch.Size([1, 5, 16])\n",
      "Mapa de atención: torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleSelfAttention(nn.Module):\n",
    "    def __init__(self, embed_dim):\n",
    "        super(SimpleSelfAttention, self).__init__()\n",
    "        self.embed_dim = embed_dim\n",
    "        \n",
    "        # Proyecciones lineales para Query, Key y Value\n",
    "        self.query = nn.Linear(embed_dim, embed_dim)\n",
    "        self.key   = nn.Linear(embed_dim, embed_dim)\n",
    "        self.value = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, embed_dim)\n",
    "        B, L, D = x.shape\n",
    "        \n",
    "        # 1. Generar Q, K, V\n",
    "        queries = self.query(x) \n",
    "        keys    = self.key(x)   \n",
    "        values  = self.value(x) \n",
    "\n",
    "        # 2. Producto punto escalado (Similitud entre palabras)\n",
    "        # Matriz de afinidad: (Q * K^T) / sqrt(d_k)\n",
    "        scores = torch.matmul(queries, keys.transpose(-2, -1)) / (self.embed_dim ** 0.5)\n",
    "        \n",
    "        # 3. Softmax para obtener pesos (probabilidades de atención)\n",
    "        attention_weights = F.softmax(scores, dim=-1)\n",
    "        \n",
    "        # 4. Multiplicar pesos por Values\n",
    "        out = torch.matmul(attention_weights, values)\n",
    "        \n",
    "        return out, attention_weights\n",
    "\n",
    "# --- Prueba rápida ---\n",
    "batch, seq_len, dim = 1, 5, 16  # 1 oración, 5 palabras, 16 dimensiones cada una\n",
    "x = torch.randn(batch, seq_len, dim)\n",
    "model = SimpleSelfAttention(dim)\n",
    "output, weights = model(x)\n",
    "\n",
    "print(f\"Salida del bloque: {output.shape}\") # Igual a la entrada\n",
    "print(f\"Mapa de atención: {weights.shape}\") # (1, 5, 5) -> Relación de cada palabra con todas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a97b595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1748, 0.1478, 0.1974, 0.1957, 0.2842],\n",
       "         [0.1474, 0.1674, 0.0995, 0.1847, 0.4010],\n",
       "         [0.1601, 0.2960, 0.2176, 0.1383, 0.1880],\n",
       "         [0.2014, 0.1060, 0.1579, 0.2761, 0.2586],\n",
       "         [0.2459, 0.1262, 0.1730, 0.2418, 0.2132]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fbc962b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input original (ceros): tensor([0., 0., 0., 0.])\n",
      "Input con posición: tensor([0., 1., 0., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        # Crear una matriz de ceros para las posiciones\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        \n",
    "        # Factor de división basado en la dimensión del modelo\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        \n",
    "        # Aplicar Seno a índices pares y Coseno a impares\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Añadir dimensión de batch: (1, max_len, d_model)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, d_model)\n",
    "        # Se suma el encoding a los embeddings originales\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x\n",
    "\n",
    "# --- Prueba ---\n",
    "d_model = 16\n",
    "pos_encoder = PositionalEncoding(d_model)\n",
    "dummy_input = torch.zeros(1, 10, d_model) # 10 palabras vacías\n",
    "output = pos_encoder(dummy_input)\n",
    "\n",
    "print(f\"Input original (ceros): {dummy_input[0,0,:4]}\")\n",
    "print(f\"Input con posición: {output[0,0,:4]}\") # Ahora tienen 'identidad' posicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3bcf0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, dropout=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        \n",
    "        # 1. Multi-Head Attention (Ya incluye las proyecciones Q, K, V internas)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=d_model, num_heads=num_heads, batch_first=True)\n",
    "        \n",
    "        # 2. Normalización y Redes Feed-Forward\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        \n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(d_model, 4 * d_model),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * d_model, d_model)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Paso A: Atención con conexión residual (Add & Norm)\n",
    "        attn_output, _ = self.attention(x, x, x) # Q, K, V son 'x' al entrar\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Paso B: Feed Forward con conexión residual (Add & Norm)\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Ejemplo de uso:\n",
    "d_model = 512\n",
    "block = TransformerBlock(d_model=d_model, num_heads=8)\n",
    "input_seq = torch.randn(1, 10, d_model) # (Batch, Seq, Dim)\n",
    "output = block(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eef4eb60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.9341, -0.9250, -0.2683,  ...,  0.8611, -0.5008, -0.1601],\n",
       "         [-0.1104,  1.9320, -0.4740,  ..., -0.5466,  0.5767, -0.8379],\n",
       "         [-0.8129,  1.3367, -2.2882,  ...,  0.6953,  0.9447,  0.0632],\n",
       "         ...,\n",
       "         [-0.9207,  2.5044, -0.5374,  ..., -0.6356, -1.9849,  1.0492],\n",
       "         [ 0.6269,  0.9470, -0.3120,  ...,  0.9391,  0.7806, -0.6197],\n",
       "         [ 0.1760,  0.1502, -0.6656,  ...,  0.2499, -0.9846, -0.2453]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
