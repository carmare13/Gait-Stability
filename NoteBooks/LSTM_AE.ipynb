{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70947ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import numpy as np\n",
    "from Data_loader import load_subjects_from_json, get_all_npy_paths_by_group, base_folders\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bbaf68a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-26 12:03:58.698350: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750950238.715268  187306 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750950238.720635  187306 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750950238.734322  187306 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750950238.734345  187306 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750950238.734347  187306 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750950238.734348  187306 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-26 12:03:58.740204: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "from AE_pipeline_pytorch import (\n",
    "    LSTMAutoencoder,\n",
    "    BiLSTMAutoencoder,\n",
    "    create_dataloader,\n",
    "    create_test_dataloader,\n",
    "    train_autoencoder,\n",
    "    evaluate_and_detect,\n",
    "    extract_and_save_latents,\n",
    "    reconstruct_and_evaluate \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78b3e2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "NUM_BIOMECHANICAL_VARIABLES = 321\n",
    "n_timesteps= 100 #cycle is normalized to 100 points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b104947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a210b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load subjects lists \n",
    "train_subjects = {\n",
    "    \"G01\": load_subjects_from_json(\"G01_train_subjects.json\"),\n",
    "    \"G03\": load_subjects_from_json(\"G03_train_subjects.json\")\n",
    "}\n",
    "val_subjects = {\n",
    "    \"G01\": load_subjects_from_json(\"G01_validation_subjects.json\"),\n",
    "    \"G03\": load_subjects_from_json(\"G03_validation_subjects.json\")\n",
    "}\n",
    "test_subjects = {\n",
    "    \"G01\": load_subjects_from_json(\"G01_test_subjects.json\"),\n",
    "    \"G03\": load_subjects_from_json(\"G03_test_subjects.json\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0159dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S030/preprocessed/S030_D01_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S030/preprocessed/S030_D01_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S030/preprocessed/S030_D01_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S030/preprocessed/S030_D01_B02_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S030/preprocessed/S030_D01_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B01_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B01_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B02_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S017/preprocessed/S017_D02_B03_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S012/preprocessed/S012_D01_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S014/preprocessed/S014_D02_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S033/preprocessed/S033_D02_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S033/preprocessed/S033_D02_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D01_B01_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D02_B01_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D02_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D02_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D02_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S031/preprocessed/S031_D02_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S039/preprocessed/S039_D01_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S039/preprocessed/S039_D01_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S039/preprocessed/S039_D01_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S034/preprocessed/S034_D01_B01_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S034/preprocessed/S034_D01_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S034/preprocessed/S034_D01_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S034/preprocessed/S034_D01_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B01_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B01_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B02_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S131/preprocessed/S131_D02_B03_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/young adults (19–35 years old)/S005/preprocessed/S005_D02_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S019/preprocessed/S019_D01_B03_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S107/preprocessed/S107_D01_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D01_B01_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B01_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B01_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B01_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B02_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B02_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B02_T03_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B03_T01_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B03_T02_preprocessed.npy\n",
      "Warning: missing file /mnt/storage/dmartinez/old adults (56+ years old)/S104/preprocessed/S104_D02_B03_T03_preprocessed.npy\n",
      "Train .npy: 932 files\n",
      " Val  .npy: 196 files\n",
      " Test .npy: 169 files\n"
     ]
    }
   ],
   "source": [
    "# Generate routes .npy\n",
    "train_npy = get_all_npy_paths_by_group(train_subjects, base_folders)\n",
    "val_npy   = get_all_npy_paths_by_group(val_subjects,   base_folders)\n",
    "test_npy  = get_all_npy_paths_by_group(test_subjects,  base_folders)\n",
    "\n",
    "print(f\"Train .npy: {len(train_npy)} files\")\n",
    "print(f\" Val  .npy: {len(val_npy)} files\")\n",
    "print(f\" Test .npy: {len(test_npy)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2103e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "# 1) DataLoader para train y validation (sin metadata)\n",
    "train_loader = create_dataloader(\n",
    "        train_npy,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        is_train=True,\n",
    "        n_timesteps=n_timesteps,\n",
    "        n_vars=NUM_BIOMECHANICAL_VARIABLES\n",
    "    )\n",
    "val_loader = create_dataloader(\n",
    "        val_npy,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        is_train=False,\n",
    "        n_timesteps=n_timesteps,\n",
    "        n_vars=NUM_BIOMECHANICAL_VARIABLES\n",
    "    )\n",
    "\n",
    "# 2) DataLoader para test (con metadata)\n",
    "test_loader = create_test_dataloader(\n",
    "        test_npy,\n",
    "        subjects_by_group=test_subjects,\n",
    "        base_folders=base_folders,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        n_timesteps=n_timesteps,\n",
    "        n_vars=NUM_BIOMECHANICAL_VARIABLES\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bacf818",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmartinez/Gait-Stability/AE_pipeline_pytorch.py:209: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/home/dmartinez/Gait-Stability/AE_pipeline_pytorch.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "/home/dmartinez/Gait-Stability/AE_pipeline_pytorch.py:222: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 100, in pin_memory\n    clone[i] = pin_memory(item, device)\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m     model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcompile(model)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Tu función de train_autoencoder acepta train_loader y val_loader\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mtrain_autoencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTorch1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m     18\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Gait-Stability/AE_pipeline_pytorch.py:219\u001b[0m, in \u001b[0;36mtrain_autoencoder\u001b[0;34m(model, train_loader, val_loader, run_id, epochs, model_dir, log_dir, lr_initial, lr_decay_rate, lr_decay_steps, clip_norm)\u001b[0m\n\u001b[1;32m    217\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m    218\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.\u001b[39m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, (x, _) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_loader):\n\u001b[1;32m    220\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device, non_blocking\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    221\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/dataloader.py:733\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    731\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    732\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 733\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    735\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    737\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    738\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    739\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1515\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1513\u001b[0m worker_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info\u001b[38;5;241m.\u001b[39mpop(idx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rcvd_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworker_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1550\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data, worker_idx)\u001b[0m\n\u001b[1;32m   1548\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1549\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1550\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/_utils.py:750\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments or otherwise can't\u001b[39;00m\n\u001b[1;32m    748\u001b[0m     \u001b[38;5;66;03m# be constructed, don't try to instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    749\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 750\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in pin memory thread for device 0.\nOriginal Traceback (most recent call last):\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 43, in do_one_step\n    data = pin_memory(data, device)\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 100, in pin_memory\n    clone[i] = pin_memory(item, device)\n  File \"/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/_utils/pin_memory.py\", line 66, in pin_memory\n    return data.pin_memory(device)\nRuntimeError: CUDA error: invalid argument\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n\n"
     ]
    }
   ],
   "source": [
    "#Train \n",
    "\n",
    "model = LSTMAutoencoder(n_timesteps=100, n_vars=321, latent_dim=128).to(device)\n",
    "\n",
    "\n",
    "# Compila el modelo (PyTorch 2.0 JIT), **antes** de entrenar\n",
    "if hasattr(torch, \"compile\"):\n",
    "    model = torch.compile(model)\n",
    "\n",
    "\n",
    "# Tu función de train_autoencoder acepta train_loader y val_loader\n",
    "train_autoencoder(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    run_id=\"Torch1\",\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "all_scores = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        recon = model(x)                       # (B, T, 321)\n",
    "        # Si quieres comparar recon vs y, quizá tu función `evaluate_and_detect`\n",
    "        # espera (x, y) y devuelve errores. Sino:\n",
    "        # ejemplo de score: media de MSE por variable\n",
    "        loss = mse(recon, x).mean(dim=(1,2))   # reconstrucción de x vs x\n",
    "        # o si tu supervisión es recon vs y:\n",
    "        # loss = mse(recon, y).mean(dim=(1,2))\n",
    "        all_scores.append(loss.cpu())\n",
    "\n",
    "all_scores = torch.cat(all_scores)\n",
    "print(\"Test MSE (batch-wise):\", all_scores.mean().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inv_Di",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
