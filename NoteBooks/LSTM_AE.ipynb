{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1bb7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70947ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-30 15:13:17.851549: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-30 15:13:17.858204: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751307197.866376 1569035 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751307197.868684 1569035 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751307197.874902 1569035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751307197.874912 1569035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751307197.874913 1569035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751307197.874914 1569035 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-30 15:13:17.877341: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import numpy as np\n",
    "\n",
    "from AE_pipeline_pytorch import (\n",
    "    LSTMAutoencoder,\n",
    "    BiLSTMAutoencoder,\n",
    "    \n",
    "    GaitBatchIterable,\n",
    "\n",
    "    train_autoencoder,\n",
    "    evaluate_and_detect,\n",
    "    extract_and_save_latents,\n",
    "    reconstruct_and_evaluate,\n",
    "    evaluate_autoencoder\n",
    ")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import zarr\n",
    "import torch.backends.cudnn as cudnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c478b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/storage/dmartinez/Gait-Stability\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee64f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader for Zarr datasets\n",
    "batch_size = 400\n",
    "train_loader = DataLoader(GaitBatchIterable(\"train_cycles.zarr\",batch_size=batch_size, return_meta=False),\n",
    "    batch_size=None,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(GaitBatchIterable(\"val_cycles.zarr\",batch_size=batch_size, return_meta=False),\n",
    "    batch_size=None,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    GaitBatchIterable(\"test_cycles.zarr\", batch_size=batch_size, return_meta=True), \n",
    "    batch_size=None, \n",
    "    num_workers=8,   \n",
    "    shuffle=False,   \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1094c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0: type=<class 'torch.Tensor'>, shape=torch.Size([400, 100, 321])\n",
      "Item 1: type=<class 'torch.Tensor'>, shape=torch.Size([400, 100, 321])\n"
     ]
    }
   ],
   "source": [
    "#To check the data loader\n",
    "batch = next(iter(train_loader))\n",
    "for i, item in enumerate(batch):\n",
    "    print(f\"Item {i}: type={type(item)}, shape={getattr(item, 'shape', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0d4ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "cudnn.benchmark = True\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bacf818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30: train_loss=0.8804, val_loss=0.7183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmartinez/miniconda3/envs/gait-stability/lib/python3.10/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <AE_pipeline_pytorch.GaitBatchIterable object at 0x71f496b3fe50> was reported to be 486(when accessing len(dataloader)), but 487 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/dmartinez/miniconda3/envs/gait-stability/lib/python3.10/site-packages/torch/utils/data/dataloader.py:718: UserWarning: Length of IterableDataset <AE_pipeline_pytorch.GaitBatchIterable object at 0x71f340efb250> was reported to be 105(when accessing len(dataloader)), but 106 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30: train_loss=0.5848, val_loss=0.6337\n",
      "Epoch 3/30: train_loss=0.5254, val_loss=0.6002\n",
      "Epoch 4/30: train_loss=0.4929, val_loss=0.5782\n",
      "Epoch 5/30: train_loss=0.4697, val_loss=0.5590\n",
      "Epoch 6/30: train_loss=0.4515, val_loss=0.5452\n",
      "Epoch 7/30: train_loss=0.4363, val_loss=0.5343\n",
      "Epoch 8/30: train_loss=0.4237, val_loss=0.5255\n",
      "Epoch 9/30: train_loss=0.4130, val_loss=0.5180\n",
      "Epoch 10/30: train_loss=0.4037, val_loss=0.5106\n",
      "Epoch 11/30: train_loss=0.3952, val_loss=0.5042\n",
      "Epoch 12/30: train_loss=0.3876, val_loss=0.4987\n",
      "Epoch 13/30: train_loss=0.3808, val_loss=0.4927\n",
      "Epoch 14/30: train_loss=0.3751, val_loss=0.4866\n",
      "Epoch 15/30: train_loss=0.3690, val_loss=0.4822\n"
     ]
    }
   ],
   "source": [
    "#Train \n",
    "\n",
    "model = BiLSTMAutoencoder(n_timesteps=100, n_vars=321, latent_dim=128).to(device)\n",
    "\n",
    "\n",
    "# Compila el modelo (PyTorch 2.0 JIT), **antes** de entrenar\n",
    "if hasattr(torch, \"compile\"):\n",
    "    model = torch.compile(model)\n",
    "\n",
    "\n",
    "# Tu funci√≥n de train_autoencoder acepta train_loader y val_loader\n",
    "train_autoencoder(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    run_id=\"Torch1\",\n",
    "    epochs=30,\n",
    "    debug=False,\n",
    "    debug_batches=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f661e73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate metrics \n",
    "model = LSTMAutoencoder(n_timesteps=100, n_vars=321, latent_dim=128).to(device)\n",
    "model.load_state_dict(torch.load(\"saved_models/ae_lstm_Torch1.pth\"))\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "metrics = evaluate_autoencoder(model, train_loader, device=device)\n",
    "print(metrics)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "all_scores = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        recon = model(x)                       # (B, T, 321)\n",
    "        # Si quieres comparar recon vs y, quiz√° tu funci√≥n `evaluate_and_detect`\n",
    "        # espera (x, y) y devuelve errores. Sino:\n",
    "        # ejemplo de score: media de MSE por variable\n",
    "        loss = mse(recon, x).mean(dim=(1,2))   # reconstrucci√≥n de x vs x\n",
    "        # o si tu supervisi√≥n es recon vs y:\n",
    "        # loss = mse(recon, y).mean(dim=(1,2))\n",
    "        all_scores.append(loss.cpu())\n",
    "\n",
    "all_scores = torch.cat(all_scores)\n",
    "print(\"Test MSE (batch-wise):\", all_scores.mean().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gait-stability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
