{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1bb7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70947ddb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-27 12:13:55.551948: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751037235.569827   87609 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751037235.575001   87609 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1751037235.587917   87609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751037235.587935   87609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751037235.587937   87609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1751037235.587939   87609 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-27 12:13:55.592743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "os.chdir('..')\n",
    "sys.path.insert(0, os.getcwd())\n",
    "import numpy as np\n",
    "\n",
    "from AE_pipeline_pytorch import (\n",
    "    LSTMAutoencoder,\n",
    "    BiLSTMAutoencoder,\n",
    "    \n",
    "    GaitBatchIterable,\n",
    "\n",
    "    train_autoencoder,\n",
    "    evaluate_and_detect,\n",
    "    extract_and_save_latents,\n",
    "    reconstruct_and_evaluate \n",
    ")\n",
    "\n",
    "import math\n",
    "import torch\n",
    "from time import time\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import zarr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c478b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/dmartinez/Gait-Stability\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b104947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ee64f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data loader for Zarr datasets\n",
    "batch_size = 400\n",
    "train_loader = DataLoader(GaitBatchIterable(\"train_cycles.zarr\",batch_size=batch_size, return_meta=False),\n",
    "    batch_size=None,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "\n",
    "\n",
    "val_loader = DataLoader(GaitBatchIterable(\"val_cycles.zarr\",batch_size=batch_size, return_meta=False),\n",
    "    batch_size=None,\n",
    "    num_workers=8,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    GaitBatchIterable(\"test_cycles.zarr\", batch_size=batch_size, return_meta=True), \n",
    "    batch_size=None, \n",
    "    num_workers=8,   \n",
    "    shuffle=False,   \n",
    "    pin_memory=True,\n",
    "    persistent_workers=True,\n",
    "    prefetch_factor=2,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1094c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item 0: type=<class 'torch.Tensor'>, shape=torch.Size([1000, 100, 321])\n",
      "Item 1: type=<class 'torch.Tensor'>, shape=torch.Size([1000, 100, 321])\n"
     ]
    }
   ],
   "source": [
    "#To check the data loader\n",
    "batch = next(iter(train_loader))\n",
    "for i, item in enumerate(batch):\n",
    "    print(f\"Item {i}: type={type(item)}, shape={getattr(item, 'shape', None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bacf818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: train_loss=0.9471, val_loss=0.9669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/dataloader.py:750: UserWarning: Length of IterableDataset <AE_pipeline_pytorch.GaitBatchIterable object at 0x746afc2bec50> was reported to be 486(when accessing len(dataloader)), but 487 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
      "  warnings.warn(warn_msg)\n",
      "/home/dmartinez/miniconda3/envs/inv_Di/lib/python3.10/site-packages/torch/utils/data/dataloader.py:750: UserWarning: Length of IterableDataset <AE_pipeline_pytorch.GaitBatchIterable object at 0x746afc2be3e0> was reported to be 105(when accessing len(dataloader)), but 106 samples have been fetched. For multiprocessing data-loading, this could be caused by not properly configuring the IterableDataset replica at each worker. Please see https://pytorch.org/docs/stable/data.html#torch.utils.data.IterableDataset for examples.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20: train_loss=0.7191, val_loss=0.7061\n",
      "Epoch 3/20: train_loss=0.5566, val_loss=0.6503\n",
      "Epoch 4/20: train_loss=0.5148, val_loss=0.6196\n",
      "Epoch 5/20: train_loss=0.4853, val_loss=0.5975\n",
      "Epoch 6/20: train_loss=0.4637, val_loss=0.5813\n",
      "Epoch 7/20: train_loss=0.4457, val_loss=0.5682\n",
      "Epoch 8/20: train_loss=0.4314, val_loss=0.5599\n",
      "Epoch 9/20: train_loss=0.4192, val_loss=0.5478\n",
      "Epoch 10/20: train_loss=0.4105, val_loss=0.5436\n",
      "Epoch 11/20: train_loss=0.4003, val_loss=0.5327\n",
      "Epoch 12/20: train_loss=0.3919, val_loss=0.5270\n",
      "Epoch 13/20: train_loss=0.3846, val_loss=0.5202\n",
      "Epoch 14/20: train_loss=0.3775, val_loss=0.5142\n",
      "Epoch 15/20: train_loss=0.3714, val_loss=0.5089\n",
      "Epoch 16/20: train_loss=0.3670, val_loss=0.5051\n",
      "Epoch 17/20: train_loss=0.3613, val_loss=0.5003\n",
      "Epoch 18/20: train_loss=0.3568, val_loss=0.4976\n",
      "Epoch 19/20: train_loss=0.3519, val_loss=0.4931\n"
     ]
    }
   ],
   "source": [
    "#Train \n",
    "\n",
    "model = LSTMAutoencoder(n_timesteps=100, n_vars=321, latent_dim=128).to(device)\n",
    "\n",
    "\n",
    "# Compila el modelo (PyTorch 2.0 JIT), **antes** de entrenar\n",
    "if hasattr(torch, \"compile\"):\n",
    "    model = torch.compile(model)\n",
    "\n",
    "\n",
    "# Tu función de train_autoencoder acepta train_loader y val_loader\n",
    "train_autoencoder(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    run_id=\"Torch1\",\n",
    "    epochs=20,\n",
    "    debug=False,\n",
    "    debug_batches=60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a2d0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "mse = torch.nn.MSELoss(reduction='none')\n",
    "\n",
    "all_scores = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        recon = model(x)                       # (B, T, 321)\n",
    "        # Si quieres comparar recon vs y, quizá tu función `evaluate_and_detect`\n",
    "        # espera (x, y) y devuelve errores. Sino:\n",
    "        # ejemplo de score: media de MSE por variable\n",
    "        loss = mse(recon, x).mean(dim=(1,2))   # reconstrucción de x vs x\n",
    "        # o si tu supervisión es recon vs y:\n",
    "        # loss = mse(recon, y).mean(dim=(1,2))\n",
    "        all_scores.append(loss.cpu())\n",
    "\n",
    "all_scores = torch.cat(all_scores)\n",
    "print(\"Test MSE (batch-wise):\", all_scores.mean().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "inv_Di",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
